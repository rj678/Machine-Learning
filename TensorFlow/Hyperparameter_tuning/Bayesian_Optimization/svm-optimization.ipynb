{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian optimization of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gp1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/Volumes/RJ_2TB/Tech/Documents/Programming/Machine Learning/TF/code/TensorFlow/Hyperparameter_tuning/Bayesian_Optimization/python/plotters.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_process\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gp1'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the Python scripts that contain the Bayesian optimization code\n",
    "%run ./python/gp1.py\n",
    "%run ./python/plotters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.gaussian_process as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how this algorithm behaves, we'll use it on a classification task. Luckily for us, scikit-learn provides helper functions like `make_classification()`, to build dummy data sets that can be used to test classifiers.\n",
    "\n",
    "We'll optimize the penalization parameter $C$, and kernel parameter $\\gamma$, of a support vector machine, with RBF kernel. The loss function we will use is the cross-validated area under the curve (AUC), based on three folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = make_classification(n_samples=2500,\n",
    "                                   n_features=45,\n",
    "                                   n_informative=15,\n",
    "                                   n_redundant=5)\n",
    "\n",
    "def sample_loss(params):\n",
    "    return cross_val_score(SVC(C=10 ** params[0], gamma=10 ** params[1], random_state=12345),\n",
    "                           X=data, y=target, scoring='roc_auc', cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a relatively simple problem, we can actually compute the loss surface as a function of $C$ and $\\gamma$. This way, we can get an accurate estimate of where the true optimum of the loss surface is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -4.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = np.linspace(1, -4, 2)\n",
    "gammas = np.linspace(1, -4, 2)\n",
    "\n",
    "# We need the cartesian combination of these two vectors\n",
    "param_grid = np.array([[C, gamma] for gamma in gammas for C in lambdas])\n",
    "\n",
    "real_loss = [sample_loss(params) for params in param_grid]\n",
    "\n",
    "# The maximum is at:\n",
    "param_grid[np.array(real_loss).argmax(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "\n",
    "C, G = np.meshgrid(lambdas, gammas)\n",
    "plt.figure()\n",
    "cp = plt.contourf(C, G, np.array(real_loss).reshape(C.shape))\n",
    "plt.colorbar(cp)\n",
    "plt.title('Filled contours plot of loss function $\\mathcal{L}$($\\gamma$, $C$)')\n",
    "plt.xlabel('$C$')\n",
    "plt.ylabel('$\\gamma$')\n",
    "plt.savefig('real_loss_contour.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the underlying GP, we'll assume a [Matern](http://scikit-learn.org/stable/modules/gaussian_process.html#matern-kernel) kernel as the covariance function. Although we skim over the selection of the kernel here, in general the behaviour of the algorithm is dependent on the choice of the kernel. Using a Matern kernel, with the default parameters, means we implicitly assume the loss $f$ is at least once differentiable. [There are a number of kernels available](http://scikit-learn.org/stable/modules/gaussian_process.html#kernels-for-gaussian-processes) in scikit-learn, and each kernel implies a different assumption on the behaviour of the loss $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array([[-4, 1], [-4, 1]])\n",
    "\n",
    "xp, yp = bayesian_optimisation(n_iters=3, \n",
    "                               sample_loss=sample_loss, \n",
    "                               bounds=bounds,\n",
    "                               n_pre_samples=3,\n",
    "                               random_search=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The animation below shows the sequence of points selected, if we run the Bayesian optimization algorithm in this setting. The star shows the value of $C$ and $\\gamma$ that result in the largest value of cross-validated AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expected_improvement' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b756c3044f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musetex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_param_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgammas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.58333333\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.15789474\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/RJ_2TB/Tech/Documents/Programming/Machine Learning/TF/code/TensorFlow/Hyperparameter_tuning/Bayesian_Optimization/python/plotters.py\u001b[0m in \u001b[0;36mplot_iteration\u001b[0;34m(first_param_grid, sampled_params, sampled_loss, first_iter, alpha, greater_is_better, true_y, second_param_grid, param_dims_to_plot, filepath, optimum)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             ei = -1 * expected_improvement(param_grid, model, sampled_loss[:(i + 1)],\n\u001b[0m\u001b[1;32m     70\u001b[0m                                            greater_is_better=greater_is_better, n_params=2)\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expected_improvement' is not defined"
     ]
    }
   ],
   "source": [
    "rc('text', usetex=False)\n",
    "plot_iteration(lambdas, xp, yp, first_iter=3, second_param_grid=gammas, optimum=[0.58333333, -2.15789474])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a gif from the images\n",
    "import imageio\n",
    "images = []\n",
    "\n",
    "for i in range(3, 23):\n",
    "    filename = \"/Users/thomashuijskens/Personal/gp-optimisation/figures/bo_iteration_%d.png\" % i \n",
    "    images.append(imageio.imread(filename))\n",
    "    \n",
    "imageio.mimsave('/Users/thomashuijskens/Personal/gp-optimisation/figures/bo_2d_new_data.gif', images, duration=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
