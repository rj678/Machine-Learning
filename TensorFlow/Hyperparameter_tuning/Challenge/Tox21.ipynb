{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required modules\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(456)\n",
    "import matplotlib.pyplot as plt\n",
    "import deepchem as dc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from /var/folders/dw/zv841rqs40l1wq1t4932b4sh0000gn/T/tox21.csv.gz\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "TIMING: featurizing shard 0 took 18.120 s\n",
      "TIMING: dataset construction took 19.136 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 2.565 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 1.527 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.759 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.752 s\n",
      "Loading dataset from disk.\n",
      "About to fit model on train set.\n",
      "Weighted train Classification Accuracy: 0.996769\n",
      "Weighted valid Classification Accuracy: 0.680170\n",
      "Weighted test Classification Accuracy: 0.650164\n"
     ]
    }
   ],
   "source": [
    "# Train and test the Tox21 dataset using the Random Forest algorithm in scikit-learn\n",
    "\n",
    "_, (train, valid, test), _ = dc.molnet.load_tox21()\n",
    "train_X, train_y, train_w = train.X, train.y, train.w\n",
    "valid_X, valid_y, valid_w = valid.X, valid.y, valid.w\n",
    "test_X, test_y, test_w = test.X, test.y, test.w\n",
    "\n",
    "# Remove extra tasks\n",
    "train_y = train_y[:, 0]\n",
    "valid_y = valid_y[:, 0]\n",
    "test_y = test_y[:, 0]\n",
    "train_w = train_w[:, 0]\n",
    "valid_w = valid_w[:, 0]\n",
    "test_w = test_w[:, 0]\n",
    "\n",
    "# Train the model\n",
    "sklearn_model = RandomForestClassifier(\n",
    "    class_weight=\"balanced\", n_estimators=50)\n",
    "print(\"About to fit model on train set.\")\n",
    "sklearn_model.fit(train_X, train_y)\n",
    "\n",
    "train_y_pred = sklearn_model.predict(train_X)\n",
    "valid_y_pred = sklearn_model.predict(valid_X)\n",
    "test_y_pred = sklearn_model.predict(test_X)\n",
    "\n",
    "# print accuracy scores\n",
    "weighted_score = accuracy_score(train_y, train_y_pred, sample_weight=train_w)\n",
    "print(\"Weighted train Classification Accuracy: %f\" % weighted_score)\n",
    "weighted_score = accuracy_score(valid_y, valid_y_pred, sample_weight=valid_w)\n",
    "print(\"Weighted valid Classification Accuracy: %f\" % weighted_score)\n",
    "weighted_score = accuracy_score(test_y, test_y_pred, sample_weight=test_w)\n",
    "print(\"Weighted test Classification Accuracy: %f\" % weighted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function to perform a grid search\n",
    "\n",
    "from fcnet_func import eval_tox21_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 5\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 1\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "epoch 0, step 0, loss: 446.149902\n",
      "epoch 0, step 1, loss: 234.444077\n",
      "epoch 0, step 2, loss: 216.360336\n",
      "epoch 0, step 3, loss: 370.723145\n",
      "epoch 0, step 4, loss: 493.688934\n",
      "epoch 0, step 5, loss: 241.417664\n",
      "epoch 0, step 6, loss: 251.523376\n",
      "epoch 0, step 7, loss: 261.556946\n",
      "epoch 0, step 8, loss: 852.065735\n",
      "epoch 0, step 9, loss: 946.692871\n",
      "epoch 0, step 10, loss: 185.214966\n",
      "epoch 0, step 11, loss: 241.288727\n",
      "epoch 0, step 12, loss: 1265.515747\n",
      "epoch 0, step 13, loss: 835.334656\n",
      "epoch 0, step 14, loss: 974.542908\n",
      "epoch 0, step 15, loss: 322.370636\n",
      "epoch 0, step 16, loss: 315.324768\n",
      "epoch 0, step 17, loss: 321.011414\n",
      "epoch 0, step 18, loss: 644.870850\n",
      "epoch 0, step 19, loss: 213.550369\n",
      "epoch 0, step 20, loss: 473.620605\n",
      "epoch 0, step 21, loss: 817.973267\n",
      "epoch 0, step 22, loss: 286.844879\n",
      "epoch 0, step 23, loss: 306.194031\n",
      "epoch 0, step 24, loss: 403.112366\n",
      "epoch 0, step 25, loss: 393.843628\n",
      "epoch 0, step 26, loss: 223.428741\n",
      "epoch 0, step 27, loss: 550.546570\n",
      "epoch 0, step 28, loss: 685.237427\n",
      "epoch 0, step 29, loss: 181.950500\n",
      "epoch 0, step 30, loss: 308.491333\n",
      "epoch 0, step 31, loss: 213.978088\n",
      "epoch 0, step 32, loss: 224.756180\n",
      "epoch 0, step 33, loss: 742.952271\n",
      "epoch 0, step 34, loss: 327.337769\n",
      "epoch 0, step 35, loss: 217.112656\n",
      "epoch 0, step 36, loss: 232.608093\n",
      "epoch 0, step 37, loss: 280.566803\n",
      "epoch 0, step 38, loss: 494.082367\n",
      "epoch 0, step 39, loss: 658.900574\n",
      "epoch 0, step 40, loss: 1049.843750\n",
      "epoch 0, step 41, loss: 543.293945\n",
      "epoch 0, step 42, loss: 219.956009\n",
      "epoch 0, step 43, loss: 505.994354\n",
      "epoch 0, step 44, loss: 280.733978\n",
      "epoch 0, step 45, loss: 266.001373\n",
      "epoch 0, step 46, loss: 329.345886\n",
      "epoch 0, step 47, loss: 342.105591\n",
      "epoch 0, step 48, loss: 392.889648\n",
      "epoch 0, step 49, loss: 173.696274\n",
      "epoch 0, step 50, loss: 285.392303\n",
      "epoch 0, step 51, loss: 415.030212\n",
      "epoch 0, step 52, loss: 288.269684\n",
      "epoch 0, step 53, loss: 355.147278\n",
      "epoch 0, step 54, loss: 424.467834\n",
      "epoch 0, step 55, loss: 156.864624\n",
      "epoch 0, step 56, loss: 229.374878\n",
      "epoch 0, step 57, loss: 397.365723\n",
      "epoch 0, step 58, loss: 2146.510498\n",
      "epoch 0, step 59, loss: 984.232666\n",
      "epoch 0, step 60, loss: 1122.204834\n",
      "epoch 0, step 61, loss: 660.234192\n",
      "epoch 0, step 62, loss: 191.284729\n",
      "Valid Weighted Classification Accuracy: 0.549076\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 5\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 1\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "epoch 0, step 0, loss: 456.763794\n",
      "epoch 0, step 1, loss: 692.784485\n",
      "epoch 0, step 2, loss: 371.611450\n",
      "epoch 0, step 3, loss: 722.720154\n",
      "epoch 0, step 4, loss: 496.925232\n",
      "epoch 0, step 5, loss: 595.654236\n",
      "epoch 0, step 6, loss: 516.594543\n",
      "epoch 0, step 7, loss: 273.449432\n",
      "epoch 0, step 8, loss: 660.266663\n",
      "epoch 0, step 9, loss: 684.526733\n",
      "epoch 0, step 10, loss: 340.418152\n",
      "epoch 0, step 11, loss: 857.562378\n",
      "epoch 0, step 12, loss: 497.861908\n",
      "epoch 0, step 13, loss: 358.245636\n",
      "epoch 0, step 14, loss: 1659.399414\n",
      "epoch 0, step 15, loss: 321.243134\n",
      "epoch 0, step 16, loss: 911.834717\n",
      "epoch 0, step 17, loss: 625.105469\n",
      "epoch 0, step 18, loss: 661.673584\n",
      "epoch 0, step 19, loss: 425.053589\n",
      "epoch 0, step 20, loss: 371.287628\n",
      "epoch 0, step 21, loss: 517.726685\n",
      "epoch 0, step 22, loss: 307.168793\n",
      "epoch 0, step 23, loss: 205.606186\n",
      "epoch 0, step 24, loss: 313.868866\n",
      "epoch 0, step 25, loss: 1082.693481\n",
      "epoch 0, step 26, loss: 221.106277\n",
      "epoch 0, step 27, loss: 1183.913818\n",
      "epoch 0, step 28, loss: 198.956116\n",
      "epoch 0, step 29, loss: 344.200867\n",
      "epoch 0, step 30, loss: 268.149536\n",
      "epoch 0, step 31, loss: 681.113892\n",
      "epoch 0, step 32, loss: 654.912781\n",
      "epoch 0, step 33, loss: 778.142761\n",
      "epoch 0, step 34, loss: 746.943909\n",
      "epoch 0, step 35, loss: 232.857117\n",
      "epoch 0, step 36, loss: 295.634766\n",
      "epoch 0, step 37, loss: 276.714783\n",
      "epoch 0, step 38, loss: 757.394836\n",
      "epoch 0, step 39, loss: 600.228760\n",
      "epoch 0, step 40, loss: 988.831909\n",
      "epoch 0, step 41, loss: 928.312378\n",
      "epoch 0, step 42, loss: 423.672668\n",
      "epoch 0, step 43, loss: 805.080444\n",
      "epoch 0, step 44, loss: 691.834961\n",
      "epoch 0, step 45, loss: 226.374084\n",
      "epoch 0, step 46, loss: 373.509094\n",
      "epoch 0, step 47, loss: 396.712799\n",
      "epoch 0, step 48, loss: 1374.415405\n",
      "epoch 0, step 49, loss: 321.465973\n",
      "epoch 0, step 50, loss: 576.705688\n",
      "epoch 0, step 51, loss: 551.620300\n",
      "epoch 0, step 52, loss: 616.770203\n",
      "epoch 0, step 53, loss: 236.654510\n",
      "epoch 0, step 54, loss: 216.733078\n",
      "epoch 0, step 55, loss: 548.297180\n",
      "epoch 0, step 56, loss: 1040.717285\n",
      "epoch 0, step 57, loss: 404.584961\n",
      "epoch 0, step 58, loss: 1860.554199\n",
      "epoch 0, step 59, loss: 806.401611\n",
      "epoch 0, step 60, loss: 632.060669\n",
      "epoch 0, step 61, loss: 525.881775\n",
      "epoch 0, step 62, loss: 291.891052\n",
      "Valid Weighted Classification Accuracy: 0.632100\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 5\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 1\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 1.000000\n",
      "---------------------------------------------\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "epoch 0, step 0, loss: 102.863983\n",
      "epoch 0, step 1, loss: 475.040985\n",
      "epoch 0, step 2, loss: 491.704010\n",
      "epoch 0, step 3, loss: 688.506409\n",
      "epoch 0, step 4, loss: 1327.735718\n",
      "epoch 0, step 5, loss: 3027.535400\n",
      "epoch 0, step 6, loss: 1360.201050\n",
      "epoch 0, step 7, loss: 583.848145\n",
      "epoch 0, step 8, loss: 1099.146362\n",
      "epoch 0, step 9, loss: 1360.026855\n",
      "epoch 0, step 10, loss: 1612.977661\n",
      "epoch 0, step 11, loss: 1107.472168\n",
      "epoch 0, step 12, loss: 887.866638\n",
      "epoch 0, step 13, loss: 1876.345215\n",
      "epoch 0, step 14, loss: 662.567566\n",
      "epoch 0, step 15, loss: 1221.268555\n",
      "epoch 0, step 16, loss: 2175.371582\n",
      "epoch 0, step 17, loss: 1183.744263\n",
      "epoch 0, step 18, loss: 2437.187012\n",
      "epoch 0, step 19, loss: 424.041168\n",
      "epoch 0, step 20, loss: 612.412476\n",
      "epoch 0, step 21, loss: 97.502823\n",
      "epoch 0, step 22, loss: 407.914764\n",
      "epoch 0, step 23, loss: 1072.838501\n",
      "epoch 0, step 24, loss: 1087.870972\n",
      "epoch 0, step 25, loss: 461.934265\n",
      "epoch 0, step 26, loss: 559.096252\n",
      "epoch 0, step 27, loss: 1809.905151\n",
      "epoch 0, step 28, loss: 796.111267\n",
      "epoch 0, step 29, loss: 122.767357\n",
      "epoch 0, step 30, loss: 1557.963501\n",
      "epoch 0, step 31, loss: 857.445984\n",
      "epoch 0, step 32, loss: 122.766533\n",
      "epoch 0, step 33, loss: 342.303040\n",
      "epoch 0, step 34, loss: 1053.835083\n",
      "epoch 0, step 35, loss: 1034.087769\n",
      "epoch 0, step 36, loss: 383.355652\n",
      "epoch 0, step 37, loss: 584.576233\n",
      "epoch 0, step 38, loss: 776.663208\n",
      "epoch 0, step 39, loss: 602.377258\n",
      "epoch 0, step 40, loss: 708.538574\n",
      "epoch 0, step 41, loss: 1774.900269\n",
      "epoch 0, step 42, loss: 635.555176\n",
      "epoch 0, step 43, loss: 439.666504\n",
      "epoch 0, step 44, loss: 677.410339\n",
      "epoch 0, step 45, loss: 787.235413\n",
      "epoch 0, step 46, loss: 503.166565\n",
      "epoch 0, step 47, loss: 518.157104\n",
      "epoch 0, step 48, loss: 1075.416260\n",
      "epoch 0, step 49, loss: 570.139343\n",
      "epoch 0, step 50, loss: 954.552368\n",
      "epoch 0, step 51, loss: 2012.618286\n",
      "epoch 0, step 52, loss: 589.483765\n",
      "epoch 0, step 53, loss: 383.833557\n",
      "epoch 0, step 54, loss: 1929.840088\n",
      "epoch 0, step 55, loss: 609.732239\n",
      "epoch 0, step 56, loss: 652.858826\n",
      "epoch 0, step 57, loss: 1165.199219\n",
      "epoch 0, step 58, loss: 1002.727112\n",
      "epoch 0, step 59, loss: 331.914093\n",
      "epoch 0, step 60, loss: 1157.561401\n",
      "epoch 0, step 61, loss: 929.835999\n",
      "epoch 0, step 62, loss: 537.821167\n",
      "Valid Weighted Classification Accuracy: 0.473065\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 5\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 1\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 1.000000\n",
      "---------------------------------------------\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "epoch 0, step 0, loss: 188.074448\n",
      "epoch 0, step 1, loss: 311.846069\n",
      "epoch 0, step 2, loss: 190.846054\n",
      "epoch 0, step 3, loss: 232.484222\n",
      "epoch 0, step 4, loss: 241.692245\n",
      "epoch 0, step 5, loss: 187.098694\n",
      "epoch 0, step 6, loss: 260.826996\n",
      "epoch 0, step 7, loss: 181.132690\n",
      "epoch 0, step 8, loss: 331.388153\n",
      "epoch 0, step 9, loss: 299.270660\n",
      "epoch 0, step 10, loss: 169.171509\n",
      "epoch 0, step 11, loss: 207.490280\n",
      "epoch 0, step 12, loss: 169.673264\n",
      "epoch 0, step 13, loss: 231.690567\n",
      "epoch 0, step 14, loss: 238.357422\n",
      "epoch 0, step 15, loss: 344.263763\n",
      "epoch 0, step 16, loss: 216.093506\n",
      "epoch 0, step 17, loss: 273.715363\n",
      "epoch 0, step 18, loss: 197.568237\n",
      "epoch 0, step 19, loss: 205.964996\n",
      "epoch 0, step 20, loss: 468.912109\n",
      "epoch 0, step 21, loss: 188.140167\n",
      "epoch 0, step 22, loss: 205.634125\n",
      "epoch 0, step 23, loss: 288.657593\n",
      "epoch 0, step 24, loss: 390.190186\n",
      "epoch 0, step 25, loss: 282.112366\n",
      "epoch 0, step 26, loss: 191.291763\n",
      "epoch 0, step 27, loss: 251.698685\n",
      "epoch 0, step 28, loss: 429.702087\n",
      "epoch 0, step 29, loss: 147.102615\n",
      "epoch 0, step 30, loss: 335.371735\n",
      "epoch 0, step 31, loss: 197.915955\n",
      "epoch 0, step 32, loss: 130.926514\n",
      "epoch 0, step 33, loss: 226.306549\n",
      "epoch 0, step 34, loss: 305.708466\n",
      "epoch 0, step 35, loss: 202.514801\n",
      "epoch 0, step 36, loss: 186.042130\n",
      "epoch 0, step 37, loss: 210.866089\n",
      "epoch 0, step 38, loss: 203.377029\n",
      "epoch 0, step 39, loss: 275.938629\n",
      "epoch 0, step 40, loss: 204.327652\n",
      "epoch 0, step 41, loss: 470.031311\n",
      "epoch 0, step 42, loss: 183.473801\n",
      "epoch 0, step 43, loss: 326.473114\n",
      "epoch 0, step 44, loss: 211.678284\n",
      "epoch 0, step 45, loss: 172.541824\n",
      "epoch 0, step 46, loss: 183.952408\n",
      "epoch 0, step 47, loss: 317.321381\n",
      "epoch 0, step 48, loss: 197.229385\n",
      "epoch 0, step 49, loss: 274.216827\n",
      "epoch 0, step 50, loss: 164.246307\n",
      "epoch 0, step 51, loss: 322.012390\n",
      "epoch 0, step 52, loss: 200.997559\n",
      "epoch 0, step 53, loss: 223.000916\n",
      "epoch 0, step 54, loss: 125.452744\n",
      "epoch 0, step 55, loss: 164.229385\n",
      "epoch 0, step 56, loss: 405.493896\n",
      "epoch 0, step 57, loss: 231.202881\n",
      "epoch 0, step 58, loss: 287.324097\n",
      "epoch 0, step 59, loss: 141.298416\n",
      "epoch 0, step 60, loss: 318.491821\n",
      "epoch 0, step 61, loss: 143.241241\n",
      "epoch 0, step 62, loss: 136.191650\n",
      "Valid Weighted Classification Accuracy: 0.435004\n",
      "All Scores\n",
      "{(5, 1, 0.5, 1): [0.5490761141892654], (5, 1, 0.5, 2): [0.6320999671539234], (5, 1, 1.0, 1): [0.47306501844894594], (5, 1, 1.0, 2): [0.4350043275305265]}\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "set up a grid search to tune hyperparameters for the Neural Network\n",
    "\n",
    "Model hyperparameters:\n",
    "\n",
    "no. of neurons per hidden layers: hidden_sizes\n",
    "\n",
    "no. of hidden layers: num_layers\n",
    "\n",
    "Learning rate\n",
    "\n",
    "no. of epochs\n",
    "\n",
    "Batch size\n",
    "\n",
    "Dropout probability\n",
    "\n",
    "'''\n",
    "\n",
    "scores = {}\n",
    "n_reps = 1\n",
    "hidden_sizes = [5]\n",
    "epochs = [1]\n",
    "dropouts = [.5, 1.0]\n",
    "num_layers = [1, 2]\n",
    "\n",
    "for rep in range(n_reps):\n",
    "  for n_epochs in epochs:\n",
    "    for hidden_size in hidden_sizes:\n",
    "      for dropout in dropouts:\n",
    "        for n_layers in num_layers:\n",
    "          score = eval_tox21_hyperparams(n_hidden=hidden_size, n_epochs=n_epochs,\n",
    "                                         dropout_prob=dropout, n_layers=n_layers)\n",
    "          if (hidden_size, n_epochs, dropout, n_layers) not in scores:\n",
    "            scores[(hidden_size, n_epochs, dropout, n_layers)] = []\n",
    "          scores[(hidden_size, n_epochs, dropout, n_layers)].append(score)\n",
    "print(\"All Scores\")\n",
    "print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tox21_hyperparams(n_hidden=hidden_size, n_epochs=n_epochs,\n",
    "                                         dropout_prob=dropout, n_layers=n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([((5, 1, 0.5, 1), [0.5490761141892654]), ((5, 1, 0.5, 2), [0.6320999671539234]), ((5, 1, 1.0, 1), [0.47306501844894594]), ((5, 1, 1.0, 2), [0.4350043275305265])])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Averaged over 1 repetitions\n",
      "{(5, 1, 0.5, 1): 0.5490761141892654, (5, 1, 0.5, 2): 0.6320999671539234, (5, 1, 1.0, 1): 0.47306501844894594, (5, 1, 1.0, 2): 0.4350043275305265}\n"
     ]
    }
   ],
   "source": [
    "avg_scores = {}\n",
    "for params, param_scores in scores.items():\n",
    "  avg_scores[params] = np.mean(np.array(param_scores))\n",
    "print(\"Scores Averaged over %d repetitions\" % n_reps)\n",
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
